unk: '[UNK]'
pad: '[PAD]'
vocab_path: './data/vocab.txt'
max_seq_len: 40
hidden_size_rnn: 200
use_stack_rnn: False
learning_rate: 0.0005
decay_step: 1800
lr_decay: 0.95
num_epoch: 300
epoch_no_imprv: 10
optimizer: "lazyadam"
summaries_dir: './results/Summaries/'
gpu: 0
word_dim: 100
batch_size: 128
keep_porb: 0.5
# checkpoint_dir
checkpoint_dir: './results/checkpoint/model'
nwords: 21128
